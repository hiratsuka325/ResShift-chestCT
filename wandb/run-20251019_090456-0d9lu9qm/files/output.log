/usr/local/lib/python3.8/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
trainer:
  target: trainer.TrainerDifIR
model:
  target: models.unet.UNetModelSwin
  ckpt_path: null
  params:
    image_size: 64
    in_channels: 3
    model_channels: 160
    out_channels: 3
    attention_resolutions:
    - 64
    - 32
    - 16
    - 8
    dropout: 0
    channel_mult:
    - 1
    - 2
    - 2
    - 4
    num_res_blocks:
    - 2
    - 2
    - 2
    - 2
    conv_resample: true
    dims: 2
    use_fp16: false
    num_head_channels: 32
    use_scale_shift_norm: true
    resblock_updown: false
    swin_depth: 2
    swin_embed_dim: 192
    window_size: 8
    mlp_ratio: 4
    cond_lq: true
    lq_size: 64
diffusion:
  target: models.script_util.create_gaussian_diffusion
  params:
    sf: 4
    schedule_name: exponential
    schedule_kwargs:
      power: 0.3
    etas_end: 0.99
    steps: 15
    min_noise_level: 0.04
    kappa: 2.0
    weighted_mse: false
    predict_type: xstart
    timestep_respacing: null
    scale_factor: 1.0
    normalize_input: true
    latent_flag: true
autoencoder:
  target: ldm.models.autoencoder.VQModelTorch
  ckpt_path: weights/autoencoder_vq_f4.pth
  use_fp16: true
  tune_decoder: false
  params:
    lora_tune_decoder: false
    embed_dim: 3
    n_embed: 8192
    ddconfig:
      double_z: false
      z_channels: 3
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0
      padding_mode: zeros
degradation:
  sf: 4
  resize_prob:
  - 0.2
  - 0.7
  - 0.1
  resize_range:
  - 0.15
  - 1.5
  gaussian_noise_prob: 0.5
  noise_range:
  - 1
  - 30
  poisson_scale_range:
  - 0.05
  - 3.0
  gray_noise_prob: 0.4
  jpeg_range:
  - 30
  - 95
  second_order_prob: 0.5
  second_blur_prob: 0.8
  resize_prob2:
  - 0.3
  - 0.4
  - 0.3
  resize_range2:
  - 0.3
  - 1.2
  gaussian_noise_prob2: 0.5
  noise_range2:
  - 1
  - 25
  poisson_scale_range2:
  - 0.05
  - 2.5
  gray_noise_prob2: 0.4
  jpeg_range2:
  - 30
  - 95
  gt_size: 256
  resize_back: false
  use_sharp: false
data:
  train:
    type: PairedImageDataset
    params:
      opt:
        dataroot_gt: ../ChestCT/HR
        dataroot_lq: ../ChestCT/LR
        dataroot_mask: ../ChestCT/mask
        meta_info_file: data/meta_info/meta_info_ChestCT_val_2715_part_60.txt
        io_backend:
          type: disk
        gt_size: 256
        use_hflip: true
        use_rot: true
        scale: 4
        phase: train
  val:
    type: PairedImageDataset
    params:
      opt:
        dataroot_gt: ../ChestCT/HR
        dataroot_lq: ../ChestCT/LR
        dataroot_mask: ../ChestCT/mask
        meta_info_file: data/meta_info/meta_info_ChestCT_val_2715_part_60.txt
        io_backend:
          type: disk
        scale: 4
        phase: val
train:
  lr: 5.0e-05
  lr_min: 2.0e-05
  lr_schedule: null
  warmup_iterations: 5000
  batch:
  - 8
  - 1
  microbatch: 8
  num_workers: 4
  prefetch_factor: 2
  weight_decay: 0
  ema_rate: 0.999
  iterations: 300000
  save_freq: 10000
  log_freq:
  - 200
  - 2000
  - 1
  local_logging: true
  tf_logging: false
  use_ema_val: true
  val_freq: 200
  val_y_channel: true
  val_resolution: ${model.params.lq_size}
  val_padding_mode: reflect
  use_amp: true
  seed: 123456
  global_seeding: false
  compile:
    flag: false
    mode: reduce-overhead
  scale: 4
division:
  division_size: 64
  overlap_size: 4
logger:
  wandb:
    project: experiment5
    name: ronbunnomama
    id: null
save_dir: results
resume: ''
cfg_path: configs/realsr_swinunet_realesrgan256.yaml
/usr/local/lib/python3.8/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

Number of parameters: 118.59M
Restoring autoencoder from weights/autoencoder_vq_f4.pth
building MemoryEfficientAttnBlock with 512 in_channels...
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
building MemoryEfficientAttnBlock with 512 in_channels...
Loading autoencoder from weights/autoencoder_vq_f4.pth...
Loaded Done
Loading LIIPS Metric: vgg...
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/vgg.pth
Loading dataset: 100%|██████████████████████████████| 60/60 [00:27<00:00,  2.20file/s]
Loading dataset: 100%|██████████████████████████████| 60/60 [00:26<00:00,  2.23file/s]
Number of images in train data set: 60
Number of images in val data set: 60
Train: 000200/300000, Loss/MSE: t(1):6.2e-01/6.2e-01, t(8):6.9e-01/6.9e-01, t(15):7.3e-01/7.3e-01, lr:1.99e-06
img stats:
  min: 74.740135
  max: 255.0
  mean: 179.1727
masked_img stats:
  min: 128.46837
  max: 196.09445
  mean: 164.2378
  shape: (341684,)
  dtype: float32
  non-zero count: 341684
masked_img2 stats:
  min: 148.19354
  max: 235.0
  mean: 182.23846
-0.0047967184534101715
-29.746026553620627
Validation: 01/60...
img stats:
  min: 64.96443
  max: 255.0
  mean: 178.60562
masked_img stats:
  min: 125.31116
  max: 201.55795
  mean: 160.79349
  shape: (619761,)
  dtype: float32
  non-zero count: 619761
masked_img2 stats:
  min: 148.20132
  max: 235.0
  mean: 180.6386
-0.004956128711124053
-29.66775936423858
Validation: 02/60...
img stats:
  min: 79.68954
  max: 255.0
  mean: 178.6718
masked_img stats:
  min: 132.64775
  max: 208.21866
  mean: 159.83128
  shape: (879526,)
  dtype: float32
  non-zero count: 879526
masked_img2 stats:
  min: 143.30006
  max: 235.0
  mean: 179.00897
-0.003702862905033133
-29.33417672618762
Validation: 03/60...
img stats:
  min: 90.57031
  max: 255.0
  mean: 178.88823
masked_img stats:
  min: 133.57098
  max: 197.14471
  mean: 158.51999
  shape: (1139305,)
  dtype: float32
  non-zero count: 1139305
masked_img2 stats:
  min: 142.4832
  max: 235.0
  mean: 176.58606
-0.002610092094335991
-28.64277676317431
Validation: 04/60...
img stats:
  min: 70.10236
  max: 255.0
  mean: 179.03471
masked_img stats:
  min: 130.53659
  max: 194.81538
  mean: 158.0971
  shape: (1345068,)
  dtype: float32
  non-zero count: 1345068
masked_img2 stats:
  min: 145.02718
  max: 235.0
  mean: 175.22755
-0.001387644855416312
-28.15610840533953
Validation: 05/60...
Traceback (most recent call last):
  File "main.py", line 71, in <module>
    trainer.train()
  File "/workspace/lung/hiratsuka/ResShift/trainer.py", line 322, in train
    self.validation()
  File "/workspace/lung/hiratsuka/ResShift/trainer.py", line 1021, in validation
    for sample in self.base_diffusion.p_sample_loop_progressive(
  File "/workspace/lung/hiratsuka/ResShift/models/gaussian_diffusion.py", line 459, in p_sample_loop_progressive
    t = th.tensor([i] * y.shape[0], device=device)
KeyboardInterrupt
Traceback (most recent call last):
  File "main.py", line 71, in <module>
    trainer.train()
  File "/workspace/lung/hiratsuka/ResShift/trainer.py", line 322, in train
    self.validation()
  File "/workspace/lung/hiratsuka/ResShift/trainer.py", line 1021, in validation
    for sample in self.base_diffusion.p_sample_loop_progressive(
  File "/workspace/lung/hiratsuka/ResShift/models/gaussian_diffusion.py", line 459, in p_sample_loop_progressive
    t = th.tensor([i] * y.shape[0], device=device)
KeyboardInterrupt
